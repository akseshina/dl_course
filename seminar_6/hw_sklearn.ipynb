{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Protein Family Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "family_classification_metadata = pd.read_table('../seminar_5/data/family_classification_metadata.tab')\n",
    "family_classification_sequences = pd.read_table('../seminar_5/data/family_classification_sequences.tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.read_csv('data/protVec_100d_3grams_without_quotes.csv', sep='\\t', header=None)\n",
    "table = table.T\n",
    "header = table.iloc[0] # grab the first row for the header\n",
    "prot2vec = table[1:] # take the data less the header row\n",
    "prot2vec.columns = header # set the header row as the df header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_families = Counter(family_classification_metadata['FamilyID']).most_common(1000)\n",
    "most_common_families = [family for (family, count) in most_common_families]\n",
    "family2num = {f: i for (i, f) in enumerate(most_common_families)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_PROTEIN_LEN = 501\n",
    "EMBED_LEN = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_proteins = family_classification_sequences['Sequences']\n",
    "all_families = family_classification_metadata['FamilyID']\n",
    "\n",
    "selected_ids = [i for i in range(len(all_proteins)) \n",
    "                  if all_families[i] in family2num and len(all_proteins[i]) <= MAX_PROTEIN_LEN]\n",
    "\n",
    "random.shuffle(selected_ids)\n",
    "\n",
    "train_ratio = 0.9\n",
    "num_train = int(len(selected_ids) * train_ratio)\n",
    "\n",
    "train_ids = selected_ids[:num_train]\n",
    "test_ids = selected_ids[num_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def embedding(protein):\n",
    "    res = np.zeros(100)\n",
    "    for i in range(0, (len(protein) - 3) // 3):\n",
    "        try:\n",
    "            res = np.add(res, prot2vec[protein[i*3: i*3 + 3]])\n",
    "        except KeyError:\n",
    "            res = np.add(res, prot2vec['<unk>'])\n",
    "\n",
    "    return np.divide(res, ((len(protein) - 3) // 3))\n",
    "\n",
    "#embedding(all_proteins[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "for i in range(len(train_ids)):\n",
    "    #if i % 2000 == 0:\n",
    "    #    print(i)\n",
    "    cur_id = train_ids[i]\n",
    "    X_train.append(embedding(all_proteins[cur_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "for i in range(len(test_ids)):\n",
    "    #if i % 2000 == 0:\n",
    "    #    print(i)\n",
    "    cur_id = test_ids[i]\n",
    "    X_test.append(embedding(all_proteins[cur_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "with  open('data/X_train.pickle', 'wb') as f:\n",
    "    pickle.dump(X_train, f)\n",
    "\n",
    "with  open('data/X_test.pickle', 'wb') as f:\n",
    "    pickle.dump(X_test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = all_families[train_ids]\n",
    "\n",
    "y_test = all_families[test_ids]\n",
    "\n",
    "with  open('data/y_train.pickle', 'wb') as f:\n",
    "    pickle.dump(y_train, f)\n",
    "    \n",
    "with  open('data/y_test.pickle', 'wb') as f:\n",
    "    pickle.dump(y_test, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nearest centroid classifier\n",
    "\n",
    "I used it because it's fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for shinkage None: 45.0%\n",
      "Accuracy for shinkage 0.2: 44.8%\n",
      "Accuracy for shinkage 5: 28.3%\n",
      "Accuracy for shinkage 10: 17.2%\n"
     ]
    }
   ],
   "source": [
    "for shrinkage in [None, .2, 5, 10]:\n",
    "    clf = NearestCentroid(shrink_threshold=shrinkage)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print('Accuracy for shinkage {}: {:3.1f}%'.format(shrinkage, np.mean(y_test == y_pred) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So my RNN model gave me 70.5% of accuracy VS 45.0% by Nearest centroid classifier."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
